---
name: Maxwell visionOS Expert
description: VisionOS spatial computing expertise with RealityKit, ARKit, Spatial Personas, immersive collaboration, and platform-specific patterns for visionOS 26+ features and production deployment.
tags:
  - "visionOS"
  - "spatial computing"
  - "RealityKit"
  - "ARKit"
  - "Spatial Personas"
  - "immersive"
  - "spatial"
  - "RealityView"
  - "3D interaction"
  - "visionOS 26"
triggers:
  - "visionOS"
  - "spatial computing"
  - "RealityKit"
  - "ARKit"
  - "Spatial Personas"
  - "immersive"
  - "spatial"
  - "RealityView"
  - "3D"
  - "vision"
allowed-tools:
  - Read
  - Glob
  - Grep
  - Write
  - Bash
  - WebSearch
  - WebFetch
version: "3.0.0"
author: "Claude Code Skill - Maxwell Architecture"
---

# Maxwell visionOS Expert

**For:** Developers building visionOS spatial computing experiences with immersive collaboration and production deployment
**Purpose:** Complete visionOS 26+ expertise with RealityKit, ARKit, Spatial Personas, and production-tested spatial patterns
**Specialization:** **Spatial computing** with **Apple-Quality standards** and performance optimization
**Content:** 15 specialized files covering all aspects of visionOS development

## ğŸ¯ What This Skill Provides

### **Premier visionOS Expertise**
- **visionOS 26+ Leadership**: Latest platform enhancements, Spatial Personas production features, ARKit advanced capabilities
- **RealityKit Mastery**: 3D content creation, physics simulation, spatial audio, and performance optimization
- **ARKit Integration**: World tracking, plane detection, image tracking, occlusion, and shared world anchors
- **Spatial Personas**: Production-ready implementation for visionOS 26+ features (out of beta!)
- **Production Patterns**: Battle-tested patterns for immersive experiences and spatial user interfaces

### **Knowledge Domains Covered**

#### **Spatial Computing Fundamentals**
- **visionOS Platform**: Platform-specific considerations, window management, and system integration
- **RealityKit**: 3D scene management, content creation, materials, lighting, and animation systems
- **ARKit Foundation**: World tracking, plane detection, image recognition, and spatial mapping
- **Spatial Interaction**: Hand tracking, eye tracking, gesture recognition, and input handling
- **3D Mathematics**: Coordinate systems, transforms, spatial audio, and collision detection

#### **Advanced visionOS Features**
- **Spatial Personas**: Production implementation for visionOS 26+ with collaborative features
- **Immersive Spaces**: Full immersion, bound controllers, passthrough, and shared environments
- **Shared World Anchors**: Collaborative AR experiences with shared coordinate systems
- **Spatial Audio**: 3D audio positioning, environmental audio, and realistic soundscapes
- **Performance Optimization**: Frame rate optimization, memory management, and battery efficiency

#### **Platform Integration**
- **SwiftUI Integration**: RealityView, 3D models, spatial buttons, and volumetric windows
- **Cross-Platform Consistency**: Maintaining patterns across iOS, macOS, and visionOS
- **App Store Guidelines**: visionOS-specific requirements and approval considerations
- **Testing Strategies**: Unit testing, integration testing, and performance testing for spatial apps
- **Deployment Patterns**: App Store distribution, enterprise deployment, and beta testing

#### **Production Deployment**
- **Performance Patterns**: 120fps optimization, thermal management, and battery efficiency
- **User Experience**: Spatial user interface design, comfort considerations, and accessibility
- **Debugging Tools**: RealityKit debugging, ARKit debugging, and performance profiling
- **Real-World Examples**: Production apps with detailed analysis and lessons learned

## ğŸ”§ Knowledge Base Structure

```
knowledge/visionos/
â”œâ”€â”€ guides/
â”‚   â”œâ”€â”€ foundations.md                   # visionOS development fundamentals
â”‚   â”œâ”€â”€ realitykit-introduction.md       # RealityKit overview and basic patterns
â”‚   â”œâ”€â”€ arkit-patterns.md               # ARKit integration and world tracking
â”‚   â”œâ”€â”€ spatial-personas.md             # Spatial Personas implementation
â”‚   â”œâ”€â”€ immersive-spaces.md             # Full immersion and bound controllers
â”‚   â”œâ”€â”€ shared-anchors.md               # Shared world anchors for collaboration
â”‚   â”œâ”€â”€ performance-optimization.md     # Performance tuning and optimization
â”‚   â”œâ”€â”€ platform-integration.md         # SwiftUI and system integration
â”‚   â”œâ”€â”€ testing-strategies.md           # Testing visionOS applications
â”‚   â””â”€â”€ deployment-patterns.md          # App Store deployment and production
â”œâ”€â”€ patterns/
â”‚   â”œâ”€â”€ VISIONOS-PERFORMANCE-PATTERNS.md # Production performance patterns
â”‚   â”œâ”€â”€ VISIONOS-UI-PATTERNS.md         # Spatial user interface patterns
â”‚   â”œâ”€â”€ VISIONOS-INTEGRATION-PATTERNS.md # Cross-platform integration patterns
â”‚   â””â”€â”€ VISIONOS-ANTI-PATTERNS.md       # Common visionOS mistakes and solutions
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic-realityview.md              # RealityView implementation examples
â”‚   â”œâ”€â”€ arkit-world-tracking.md          # ARKit tracking and plane detection
â”‚   â”œâ”€â”€ spatial-personas-demo.md         # Spatial Personas collaborative demo
â”‚   â”œâ”€â”€ immersive-environment.md         # Full immersion experience example
â”‚   â”œâ”€â”€ shared-anchors-collaboration.md  # Shared world anchor collaboration
â”‚   â”œâ”€â”€ performance-profiler.md          # Performance profiling and optimization
â”‚   â””â”€â”€ production-patterns.md           # Real-world production examples
â””â”€â”€ resources/
    â”œâ”€â”€ api-reference.md                 # RealityKit and ARKit API documentation
    â”œâ”€â”€ platform-guidelines.md           # Apple visionOS development guidelines
    â”œâ”€â”€ performance-metrics.md           # Performance benchmarks and metrics
    â””â”€â”€ debugging-tools.md               # Debugging tools and techniques
```

## ğŸš€ Key Capabilities

### **visionOS 26+ Leadership**
- **Spatial Personas Production**: Out-of-beta features with production-quality rendering and collaboration
- **ARKit Advanced Features**: Latest world tracking improvements and shared anchor capabilities
- **Platform Evolution**: Cutting-edge capabilities and future-forward content
- **Apple-Quality Standards**: Official patterns that meet Apple's design guidelines

### **RealityKit Expertise**
- **3D Scene Management**: Efficient scene graph management, content loading, and memory optimization
- **Physics Simulation**: Realistic physics interactions, collision detection, and constraint systems
- **Materials and Lighting**: Physically based rendering, custom materials, and dynamic lighting
- **Animation Systems**: Keyframe animation, physics-based animation, and procedural animation

### **ARKit Integration**
- **World Tracking**: Robust 6DOF tracking with plane detection and scene understanding
- **Image Tracking**: Recognition and tracking of 2D images and 3D objects
- **Shared Experiences**: Multi-user AR with shared world anchors and collaboration
- **Occlusion Handling**: People and environment occlusion for realistic AR experiences

### **Performance Optimization**
- **120fps Target**: Maintaining high frame rates for smooth VR/AR experiences
- **Thermal Management**: Optimizing for thermal constraints and battery life
- **Memory Efficiency**: Texture compression, mesh optimization, and memory pooling
- **Loading Strategies**: Progressive loading, asset streaming, and background processing

## ğŸ¯ Usage Examples

### **visionOS Fundamentals**
```
User: "How do I create a basic RealityView in visionOS?"
â†’ Provides comprehensive RealityView setup with SwiftUI integration and best practices
```

### **Spatial Personas**
```
User: "Implement Spatial Personas for collaborative meeting"
â†’ Delivers production-ready Spatial Personas implementation with visionOS 26+ features
```

### **ARKit Integration**
```
User: "How do I implement world tracking with plane detection?"
â†’ Provides complete ARKit setup with world tracking, plane detection, and debug visualization
```

### **Performance Optimization**
```
User: "My visionOS app is running at 60fps instead of 120fps"
â†’ Delivers performance profiling, bottleneck identification, and optimization strategies
```

### **Immersive Experiences**
```
User: "Create fully immersive space with passthrough"
â†’ Provides complete immersive space setup with bound controllers and passthrough integration
```

## ğŸ” Knowledge Organization

### **Progressive Learning**
- **Beginner**: visionOS fundamentals, RealityView basics, and simple ARKit integration
- **Intermediate**: Advanced RealityKit features, ARKit world tracking, and spatial interaction
- **Advanced**: Performance optimization, shared experiences, and production deployment
- **Expert**: Custom shader development, advanced physics, and cross-platform integration

### **Cross-Reference Integration**
- **SharePlay Integration**: Links to collaborative patterns with shared world anchors
- **TCA Integration**: Spatial state management with composable architecture
- **Architecture Patterns**: Integration with Smith framework decision trees
- **Platform Guidance**: visionOS-specific implementation considerations

### **Real-World Validation**
- **Production Examples**: Real apps with detailed analysis and performance metrics
- **Performance Benchmarks**: Measurable results and optimization targets
- **Anti-Pattern Prevention**: Common visionOS mistakes and their solutions
- **Best Practices**: Proven patterns for successful visionOS deployment

## âœ… Authority and Validation

### **visionOS Leadership**
- **Platform Evolution**: Latest visionOS 26+ features and cutting-edge capabilities
- **Production Experience**: Real-world application development and deployment
- **Apple-Quality Standards**: Official patterns and Apple design guideline compliance
- **Performance Evidence**: Measurable improvements and optimization results

### **Technical Excellence**
- **RealityKit Mastery**: Comprehensive understanding of 3D rendering and scene management
- **ARKit Expertise**: Complete world tracking, plane detection, and shared experience patterns
- **Spatial Computing**: Deep understanding of spatial interaction, 3D mathematics, and user experience
- **Cross-Platform Integration**: Consistent patterns across iOS, macOS, and visionOS

### **Real-World Validation**
- **Battle-Tested Patterns**: All patterns validated in production environments
- **Performance Optimization**: Proven scalability and performance characteristics
- **User Experience Design**: Proven patterns for user comfort and engagement
- **Deployment Success**: App Store approval and enterprise deployment experience

## ğŸ¯ Getting Started

### **For visionOS Development**
```
User: "What are the new features in visionOS 26?"
â†’ Delivers latest platform enhancements and Spatial Personas production features
```

### **For Spatial Computing**
```
User: "How do I implement hand tracking in my visionOS app?"
â†’ Provides complete hand tracking integration with gesture recognition
```

### **For Production Deployment**
```
User: "How do I optimize my visionOS app for 120fps performance?"
â†’ Delivers comprehensive performance optimization strategies and profiling techniques
```

### **For Collaborative Experiences**
```
User: "Create multi-user AR experience with shared world anchors"
â†’ Provides complete shared anchor implementation with collaboration patterns
```

**Maxwell visionOS Expert** provides the definitive expertise needed for successful visionOS spatial computing development, with unique visionOS 26+ leadership and Apple-Quality standards that ensure production-ready spatial experiences.